{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "src_dir = \"../../src\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from package.constants import *\n",
    "from package.datasets import *\n",
    "from package.metrics import *\n",
    "from package.model_selection import *\n",
    "from package.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train = load_processed(overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/135896\n",
    "is_train = (train[\"date\"] >= train_start_date) & (train[\"date\"] <= validation_end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train[is_train].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# See https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/149754\n",
    "dataset = create_dataset(\n",
    "    train,\n",
    "    is_train,\n",
    "    features,\n",
    "    transformed_target,\n",
    "    categorical_feature=categorical_features,\n",
    "    free_raw_data=False,\n",
    "    weight=train.loc[is_train, \"sell_price\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 3\n",
    "folds = Folds(train.loc[is_train, \"date\"], n_folds=n_folds)\n",
    "weight_start_d = train_days + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train\n",
    "del is_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "best_iterations = []\n",
    "best_scores = []\n",
    "\n",
    "for i, (train_index, valid_index) in enumerate(folds):\n",
    "    dtrain = dataset.subset(train_index)\n",
    "    dvalid = dataset.subset(valid_index)\n",
    "    evaluator = WRMSSEEvaluator(\n",
    "        train_days - (n_folds - i - 1) * evaluation_days + 1,\n",
    "        weight_start_d=weight_start_d,\n",
    "        target_transform=True,\n",
    "    )\n",
    "\n",
    "    booster = lgb.train(\n",
    "        lgb_params,\n",
    "        dtrain,\n",
    "        categorical_feature=categorical_features,\n",
    "        early_stopping_rounds=500,\n",
    "        feval=evaluator.feval,\n",
    "        num_boost_round=10_000,\n",
    "        valid_sets=[dvalid],\n",
    "        verbose_eval=100,\n",
    "    )\n",
    "\n",
    "    best_iterations.append(booster.best_iteration)\n",
    "    best_scores.append(booster.best_score[\"valid_0\"][\"wrmsse\"])\n",
    "\n",
    "best_iteration = int(np.mean(best_iterations))\n",
    "best_score = np.mean(best_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = lgb.train(lgb_params, dataset, num_boost_round=best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "joblib.dump(model, lgbm_reg_path)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
